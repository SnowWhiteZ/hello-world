
Name:LDC2013T21.tgz： https://wakespace.lib.wfu.edu/bitstream/handle/10339/39379/LDC2013T21.tgz?sequence=1

toutiao_data.csv: 
    今日头条中文新闻（文本）分类数据集 
    每行为一条数据，以!分割的个字段，从前往后分别是 新闻ID，分类code（见下文），分类名称（见下文），新闻字符串（仅含标题），新闻关键词。
    来源: https://github.com/mattzheng/LangueOne/toutiao_data.rar; https://github.com/fateleak/toutiao-text-classfication-dataset.git

GoogleNews-vectors-negative300.bin.gz
    https://github.com/3Top/word2vec-api
    https://pan.baidu.com/s/1kTCQqft

/home/gswyhq/data/kaggle_dogs-vs-cats
猫狗分类数据集不包含在 Keras 中。它由 Kaggle 在 2013 年末公开并作为一项计算视觉竞赛的一部分,当时卷积神经网络还不是主流算法。
# 你可以从 https://www.kaggle.com/c/dogs-vs-cats/data 下载原始数据集
#  数据集 链接：https://pan.baidu.com/s/13hw4LK8ihR6-6-8mpjLKDA 密码：dmp4

icwb2-data.rar
    http://sighan.cs.uchicago.edu/bakeoff2005/data/icwb2-data.rar

SogouC.reduced.zip
    https://pan.baidu.com/s/1pLrORJt

蛋白质功能预测：
https://github.com/tbepler/protein-sequence-embedding-iclr2019
- [SCOPe data](http://bergerlab-downloads.csail.mit.edu/bepler-protein-sequence-embeddings-from-structure-iclr2019/scope.tar.gz)
- [Pfam data](http://bergerlab-downloads.csail.mit.edu/bepler-protein-sequence-embeddings-from-structure-iclr2019/pfam.tar.gz)
- [Protein secondary structure data](http://bergerlab-downloads.csail.mit.edu/bepler-protein-sequence-embeddings-from-structure-iclr2019/secstr.tar.gz)
- [Transmembrane data](http://bergerlab-downloads.csail.mit.edu/bepler-protein-sequence-embeddings-from-structure-iclr2019/transmembrane.tar.gz)
- [CASP12 contact map data](http://bergerlab-downloads.csail.mit.edu/bepler-protein-sequence-embeddings-from-structure-iclr2019/casp12.tar.gz)

词性标注@人民日报199801.txt
https://pan.baidu.com/s/1gd6mslt

中华古诗词数据库
最全中华古诗词数据集，唐宋两朝近一万四千古诗人, 接近5.5万首唐诗加26万宋诗. 两宋时期1564位词人，21050首词。
https://github.com/chinese-poetry/chinese-poetry

汉语拆字字典
https://github.com/kfcd/chaizi

中华新华字典数据库。包括歇后语，成语，词语，汉字。
https://github.com/pwxcoo/chinese-xinhua

中文实体情感知识库
刻画人们如何描述某个实体，包含新闻、旅游、餐饮，共计30万对。
https://github.com/rainarch/SentiBridge

# 《TensorFlow+Keras深度学习人工智能实践应用》随书示例
https://pan.baidu.com/s/1c2rXnH2#list/path=%2FMP21710_example.zip
MP21710_example.zip

分词数据集 people-2014.7z：
数据集: https://pan.baidu.com/s/1EtXdhPR0lGF8c7tT8epn6Q 验证码: yj9j

http://183.61.19.162/zdoc/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA(%E7%AC%AC3%E7%89%88).pdf
http://183.61.19.162/zdoc/算法导论(第3版).pdf

七律百科知识图谱
7lore.zip
http://openkg.cn/dataset/7lore
http://openkg1.oss-cn-beijing.aliyuncs.com/30ee798a-3199-4de4-9792-7746bc8891e0/7lore.zip
7Lore_triple.csv

语音合成：
https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2
http://cn-mirror.openslr.org/resources/47/primewords_md_2018_set1.tar.gz

聊天语料：
raw_chat_corpus.zip
存在 https://pan.baidu.com/s/1szmNZQrwh9y994uO8DFL_A 提取码：f2ex 中。

百度中文问答数据集：
https://pan.baidu.com/s/1QUsKcFWZ7Tg1dk_AbldZ1A, 提取码：2dva
WebQA.v1.0.7z

mnist.npz:
下载链接：https://pan.baidu.com/s/1jH6uFFC 密码: dw3d
测试keras的代码时显示需要下载'https://s3.amazonaws.com/img-datasets/mnist.npz'，下载了多次都无法访问该地址，致使测试搁置。翻墙下载下来，需要的可以从这里下载解压后放在~/.keras/datases/里面，然后可以运行。

aclImdb.zip
http://s3.amazonaws.com/text-datasets/aclImdb.zip
原始 IMDB 电影评论数据集(不是使用 Keras 内置的已经预先分词的 IMDB 数据)

Keras 内置的IMDB 数据
将从https://s3.amazonaws.com/text-datasets/imdb.npz 下载数据到：.keras/datasets/imdb.npz
链接：https://pan.baidu.com/s/1L7rNOHsFsAJSNirWM4ykMw 密码：kjpa

wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
tar zxvf aclImdb_v1.tar.gz

2014 年英文维基百科的预计算嵌入
这是一个 822 MB 的压缩文件,文件名是 glove.6B.zip,里面包含 400 000 个单词(或非单词的标记)的 100 维嵌入向量。
http://nlp.stanford.edu/data/glove.6B.zip

glove.6B.zip
http://nlp.stanford.edu/data/glove.6B.zip

花卉图像数据集下载
http://download.tensorflow.org/example_images/flower_photos.tgz
5种花卉类型，接近4000张图像，分为训练集与测试集。

atec_nlp_sim_train.csv
相似度匹配语料
数据来源： https://github.com/ziweipolaris/atec2018-nlp.git

保险问答用户日志.xlsx

zhrs_faq_8_updateqa_question_answer.json
一些保险相关相似句

意图识别数据_all.txt

cased_L-24_H-1024_A-16.zip
https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip
https://github.com/zihangdai/xlnet

人脸检测预训练模型
https://github.com/ChiCheng123/SRN
SRN.pth
https://pan.baidu.com/share/init?surl=ambmu1Bu6Oi7zTcEnigFyg 密码：6fba

chinese_wwm_L-12_H-768_A-12.zip
中文全词覆盖BERT模型
https://github.com/ymcui/Chinese-BERT-wwm
https://mp.weixin.qq.com/s/nlFXfgM5KKZXnPdwd97JYg

task_data.tgz 任务数据
ERNIE_stable.tgz 模型，包含预训练模型参数
https://github.com/PaddlePaddle/LARK/tree/develop/ERNIE

ChnSentiCorp_htl_all.csv
7000 多条酒店评论数据，5000 多条正向评论，2000 多条负向评论
https://github.com/SophonPlus/ChineseNlpCorpus/raw/master/datasets/ChnSentiCorp_htl_all/ChnSentiCorp_htl_all.csv

waimai_10k.csv
某外卖平台收集的用户评价，正向 4000 条，负向 约 8000 条
https://raw.githubusercontent.com/SophonPlus/ChineseNlpCorpus/master/datasets/waimai_10k/waimai_10k.csv

online_shopping_10_cats.zip
10 个类别，共 6 万多条评论数据，正、负向评论各约 3 万条， 包括书籍、平板、手机、水果、洗发水、热水器、蒙牛、衣服、计算机、酒店
https://github.com/SophonPlus/ChineseNlpCorpus/raw/master/datasets/online_shopping_10_cats/online_shopping_10_cats.zip

weibo_senti_100k.zip
10 万多条，带情感标注 新浪微博，正负向评论约各 5 万条
https://pan.baidu.com/s/1DoQbki3YwqkuwQUOj64R_g

simplifyweibo_4_moods.zip
36 万多条，带情感标注 新浪微博，包含 4 种情感，其中喜悦约 20 万条，愤怒、厌恶、低落各约 5 万条
https://pan.baidu.com/s/16c93E5x373nsGozyWevITg

dmsc
movies.csv ratings.zip
 28 部电影，超 70 万 用户，超 200 万条 评分/评论 数据
https://pan.baidu.com/s/1c0yn3TlkzHYTdEBz3T5arA#list/path=%2F

yf_dianping
ratings.zip links.csv restaurants.csv
https://pan.baidu.com/s/1yMNvHLl6QYsGbjT7u51Nfg
24 万家餐馆，54 万用户，440 万条评论/评分数据

yf_amazon
https://pan.baidu.com/s/1SbfpZb5cm-g2LmnYV_af8Q
52 万件商品，1100 多个类目，142 万用户，720 万条评论/评分数据

微博实体识别.
https://github.com/hltcoe/golden-horse

ez_douban
5 万多部电影（3 万多有电影名称，2 万多没有电影名称），2.8 万 用户，280 万条评分数据
https://pan.baidu.com/s/1DkN1LmdSMzm_jCBKhbPbig

ACL2019-DuConv
数据下载地址：
http://ai.baidu.com/broad/download

Knowledge Extraction
知识抽取，标注的三元组数据
https://github.com/chenwanyuan/knowledge_extraction/blob/master/data/corpu.tar.gz

MS-Celeb-1M 名人图片数据集
https://hyper.ai/datasets/5543

CCKS 2018 微众银行智能客服问句匹配大赛
10w对左右的标注训练问句对数据集和1w对左右的验证问句对数据集。
https://biendata.com/competition/CCKS2018_3/datadescribe/
https://github.com/zoulala/CCKS_QA/blob/master/data/task3_train.txt

# 旅行险日志：
zdal_log

语义匹配语料：
new_esim
LCQMC
sentencesim
chinese_sts_corpus
ChineseSTSCorpus = CCKS + LCQMC + sentencesim + chinese_sts_corpus

Iris Data Set(鸢尾属植物数据集)
iris.data 
http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data

腾讯超过800万个中文单词和短语提供200维矢量表示
https://ai.tencent.com/ailab/nlp/data/Tencent_AILab_ChineseEmbedding.tar.gz

cipslong.v1
搜狗阅读理解比赛	大概80k的数据集

dureader_raw
阅读理解数据，百度dureader	100k的问答集

ChineseSTSListCorpus
dureader的文章title	20k类，大概可以生成 400K个不重复的句子对

preprocessed
百度知道数据；包括一些相似句等；

nietzsche.txt
#尼采的一些作品
https://s3.amazonaws.com/text-datasets/nietzsche.txt

cc.zh.300.vec
wiki，200万，300维的词向量

WordVector_60dimensional
60维维基百科词向量
https://pan.baidu.com/s/1o8f1ELs

