
docker 容器启动不了，报错：
max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]

解决方法，在宿主机上运行下命令即可：
zy@ubuntu:~/docker/elasticsearch$ sudo sysctl -w vm.max_map_count=262144


Elasticsearch 网络设置
network.host
节点将绑定到一个主机名或者 ip 地址并且会将该这个节点通知集群中的其他节点。接受 ip 地址，主机名，指定值或者包含这些值的数组
默认值：local
discovery.zen.ping.unicast.hosts
为了加入集群，一个节点至少需要知道集群中其他节点的主机名或者 ip 地址。这个设置提供初始其他节点列表，当前节点将尝试联系。接收 ip 地址或者主机名。
默认值：["127.0.0.1", "[::1]"]
http.port
HTTP 请求通信端口。接收单值或者一个范围。如果指定一个范围，该节点将会绑定范围的第一个可用顶点。
默认值：9200-9300
transport.tcp.port
节点间通信端口。接收单值或者一个范围。如果指定一个范围，该节点将会绑定范围的第一个可用顶点。
默认值：9300-9400

network.host 的特殊值
以下特殊值将可以传递给 network.host：

[networkInterface] 网络接口的地址，例如 en0。
local 系统中的回路地址，例如 127.0.0.1。
site 系统中任何的本地站点地址，例如 192.168.0.1。
global 系统中的任何全局作用域地 8.8.8.8。
IPv4 vs IPv6

默认情况下这些特殊值都可以在 IPv4 和IPv6 中使用，但是你可以使用 :ipv4，:ipv6 字符限制使用。例如，en0:ipv4 将绑定 en0 接口的 IPv4 地址。
Tip：在云上使用，更多特别设定可用，当你在 AWS 云或者 Google Compute Engine 云上使用时

高级网络配置
在常用的网络配置中解释的 network.host 是快捷方式，同时设置绑定地址和发布地址。在高级使用情况下，例如在一个代理服务器中运行，你可能需要设置如下不同的值：
network.bind_host
这将指定用于监听请求的网络接口。一个节点可以绑定多个接口，例如有两块网卡，一个本地站点地址，一个本地地址。
默认值：network.host
network.publish_host
发布地址，一个单一地址，用于通知集群中的其他节点，以便其他的节点能够和它通信。当前，一个 elasticsearch 节点可能被绑定到多个地址，但是仅仅有一个发布地址。如果没有指定，这个默认值将为 network.host 配置中的最好地址，以 IPv4/Ipv6 堆栈性能，之后以稳定性排序。
上述两个设置可以向 network.host 那样被设置--他们都接受 IP 地址，主机名和特定值

高级 TCP 设置
任何使用 TCP（像 HTTP 和 Transport 模块）共享如下设置：

network.tcp.no_delay 开启或关闭 TCP 无延迟设置。默认值为 true。
network.tcp.keep_alive 开启或关闭 TCP 长连接，默认值为 true。
network.tcp.reuse_address 一个地址是否可以被重用。在非 windows 机子上默认值为 true。
network.tcp.send_buffer_size TCP 发送缓冲区大小（以size unit指定）。没有默认值。
network.tcp.receive_buffer_size TCP 接收缓冲区大小（以size unit指定）。没有默认值。
Transport 和 HTTP 协议
一个Elasticsearch节点暴露两个网络协议配置继承上面的设置，但可独立地进一步配置两个网络协议：
TCP Transport
用于集群中节点之间的通信。
HTTP
暴露基于 HTTP JSON 请求接口，被所有客户端使用，比局限于 Java 客户端。

network.bind_host: 192.168.0.1
设置绑定的ip地址，默认情况下，ElasticSearch使用0.0.0.0地址，并为http传输开启9200-9300端口，
为节点到节点的通信开启9300-9400端口，也可以自行设置IP地址：，绑定这台机器的任何一个ip。

network.publish_host: 192.168.0.1
设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。

network.host: 192.168.0.1
这个参数是用来同时设置bind_host和publish_host上面两个参数。

有时候报错：
Caused by: while scanning a simple key
 in 'reader', line 9, column 1:
    discovery.zen.minimum_master_nodes:2
    ^
could not find expected ':'
 in 'reader', line 11, column 1:
    discovery.zen.ping.multicast.ena ...
    ^
解决方案：
参数冒号后加空格,或者是数组中间加空格
例如:
# discovery.zen.minimum_master_nodes: 3

有时候报错：
[2018-03-02T01:46:36,072][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [master] uncaught exception in thread [main]
org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: unknown setting [discovery.zen.ping.multicast.enabled] please check that any required plugins are installed, or check the breaking changes documentation for removed settings

解决方案：
es1.0 版本的集群的discovery默认采用的是组播（multicast）模式，但是在es2.2版本中已去除该模式，虽然提供了multicast的插件，但是官方说不建议采用multicast的模式，故我们只能采用单播(unicast)模式。
删除`elasticsearch.yml`文件中如下的配置即可
# 禁止当前节点发现多个集群节点，默认值为true：
# 这个设置把组播的自动发现给关闭了，为了防止其他机器上的节点自动连入。
discovery.zen.ping.multicast.enabled: false

有时候报错：
org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: unknown setting [discovery.zen.ping.timeout] did you mean any of [discovery.zen.ping_timeout, discovery.zen.fd.ping_timeout, discovery.zen.join_timeout, discovery.zen.publish_timeout, discovery.zen.commit_timeout]?
`elasticsearch.yml`文件中如下的配置
discovery.zen.ping.timeout: 120s
改为：
discovery.zen.ping_timeout: 120s

有时候报错：
org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];\n
`elasticsearch.yml`文件中如下的配置
network.host: 0.0.0.0
http.port: 9200

# 一次请求超过一万条记录时候，会报错：
Result window is too large, from + size must be less than or equal to: [10000] but was [30000].
ES默认的分页机制一个不足的地方是，比如有5010条数据，当你仅想取第5000到5010条数据的时候，ES也会将前5000条数据加载到内存当中，所以ES为了避免用户的过大分页请求造成ES服务所在机器内存溢出，默认对深度分页的条数进行了限制，默认的最大条数是10000条，这是正是问题描述中当获取第10000条数据的时候报Result window is too large异常的原因。
要解决这个问题，可以使用下面的方式来改变ES默认深度分页的index.max_result_window 最大窗口值
curl -XPUT http://127.0.0.1:9200/my_index/_settings -d '{ "index" : { "max_result_window" : 500000}}'
其中my_index为要修改的index名，500000为要调整的新的窗口数。将该窗口调整后，便可以解决无法获取到10000条后数据的问题。
注意事项
通过上述的方式解决了我们的问题，但也引入了另一个需要我们注意的问题，窗口值调大了后，虽然请求到分页的数据条数更多了，但它是用牺牲更多的服务器的内存、CPU资源来换取的。

# 问题： _update更新es数据时，报错：
version conflict, current version [14] is different than the one provided [13]
# 分析： 主要原因是因为多线程间的并发引起的，es的后台都是多线程异步的，多个修改请求，是没有顺序的，例如后修改的先到。
es内部的多线程异步并发是基于自己的verison版本号进行乐观锁控制的，在后修改的先到时，filed=test3，version =2,修改后到时，先修改filed=test2,veriosn=1,此时会比较veriosn，是否相等，如果不相等的话，就直接丢弃这条数据了。
在检索(retrieve)和重建索引(reindex)中保持更小的窗口，如何减少冲突性变更发生的概率，不过这些无法被完全避免，像一个其他进程在update进行重建索引时修改了文档这种情况依旧可能发生。
为了避免丢失数据，update API在检索(retrieve)阶段检索文档的当前_version，然后在重建索引(reindex)阶段通过index请求提交。如果其他进程在检索(retrieve)和重加索引(reindex)阶段修改了文档，_version将不能被匹配，然后更新失败。
对于多用户的局部更新，文档被修改了并不要紧。例如，两个进程都要增加页面浏览量，增加的顺序我们并不关心——如果冲突发生，我们唯一要做的仅仅是重新尝试更新既可。
# 解决方案： 这些可以通过retry_on_conflict参数设置重试次数来自动完成，这样update操作将会在发生错误前重试——这个值默认为0。
POST /website/pageviews/1/_update?retry_on_conflict=5 <1>
{
   "script" : "ctx._source.views+=1",
   "upsert": {
       "views": 0
   }
}
<1> 在错误发生前重试更新5次

通过`_update_by_query`, `_delete_by_query`,更新es数据时，有时候也会报版本冲突的错误，这个时候指定的conflicts=proceed参数。
当update_by_query执行的时候，也应用了ES内部的version以支持到版本控制 ，也就是说，我们在执行过程可能会出现版本冲突的问题。
默认情况下，update_by_query在遇到版本冲突问题时，同样返回409错误码，如果需求场景是不介意版本冲突的，那么可以按照上文那样，通过指定conflicts=proceed，从而当出现版本冲突时，ES将会继续执行更新的操作。
POST crm/_update_by_query?conflicts=proceed

默认情况下，版本冲突会中止_reindex过程，但您可以通过"conflicts": "proceed"请求正文中的设置对它们进行设置：
POST _reindex
{
  "conflicts": "proceed", 
  "source": {
    "index": "gaoyh"
  },
  "dest": {
    "index": "index_test",
    "op_type": "create"
  }
}
加上"conflicts": "proceed"后响应结果中不会具体显示failures。
但是，版本冲突时并未造成reindex过程中止。

异常情况： ES请求好卡，多数情况下是timeout; 查看es日志记录发现好多gc记录
原因：5.0默认分配jvm空间大小为2g 5.0之前好像是1g；数据量过多，导致es内存不足。
解决方法:-e ES_JAVA_OPTS="-Xms4g -Xmx4g" //设置初始内存 和最大内存
docker run -d -p 9200:9200 --name="es" -e ES_JAVA_OPTS="-Xms4g -Xmx4g" elasticsearch:5.6
docker run -d --name elasticsearch_18200 -p 18200:9200 -p 18300:9300 -e "xpack.security.enabled=false" -e "ELASTIC_CONTAINER=true" -e "JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk" -e "discovery.type=single-node" -e "ES_JAVA_OPTS=-Xms4096m -Xmx4096m" -v /etc/localtime:/etc/localtime -v /data/elasticsearch:/usr/share/elasticsearch/data  elasticsearch:6.6.0

# 重新索引数据时报错：
"reason":"failed to parse [id]","caused_by":{"type":"number_format_exception","reason":"For input string: \"rob_mother\""
原因是因为id 字段的数据不干净，有int类型，也有字符串类型，故而导致报错；
解决方案，先定义索引的mapping,再重新索引数据：
第一步： 定义mappings
curl -XPUT 'http://localhost:9200/test_ms_faq_20190117_173633' -d '
{
    "mappings": {
        "1": {
            "properties": {"issetting": {"type": "integer"}, "timestamp": {"type": "text"}, "chanpin_name": {"type": "text"}, "ukey": {"type": "text"}, "query_question": {"type": "text"},
                           "id": {"type": "text"},
                           "answer": {"type": "text"},
                           "similar_question": {"type": "text"},
                           "question": {"type": "text"}}
        }
    }
}
'
第二步：重新索引数据：
curl -XPUT 'http://localhost:9200/test_ms_faq_20190117_173633' -d '
{
  "source": {
    "index": "old_faq_20190117_173633"
  },
  "dest": {
    "index": "test_ms_faq_20190117_173633"
  }
}
'
