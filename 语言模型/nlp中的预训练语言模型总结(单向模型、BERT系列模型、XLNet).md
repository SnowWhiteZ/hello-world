
nlp中的预训练语言模型总结(单向模型、BERT系列模型、XLNet)

单向特征表示的自回归预训练语言模型，统称为单向模型：
ELMO/ULMFiT/SiATL/GPT1.0/GPT2.0；

双向特征表示的自编码预训练语言模型，统称为BERT系列模型：
(BERT/MASS/UNILM/ERNIE1.0/ERNIE(THU)/MTDNN/ERNIE2.0/SpanBERT/RoBERTa)

双向特征表示的自回归预训练语言模型：XLNet；


[nlp中的预训练语言模型总结](https://mp.weixin.qq.com/s/TLIV0AXgdYupIHpyDlFplw)
[Transformer 模型是怎样实现的](https://mp.weixin.qq.com/s/RwbiEfYUBJKkwwG1YtfvXw)
[XLNet预训练模型](https://mp.weixin.qq.com/s/35JrYKJGtoS1c93rKJGHEA)


