
load一个bert微调后的模型时
model = load_model('/home/gswyhq/hello-world/bert/model.h5')
报错：
ImportError: cannot import name 'TokenEmbedding'
问题分析
当我们自定义loss或者layer时，如果直接进行训练后模型文件加载，将会出现Value error 或layer 不存在等问题。
解决方案：
在Keras中，如果存在自定义layer或者loss，需要在load_model()中以字典形式指定layer或loss。如：

from keras_bert.layers.embedding import TokenEmbedding
from keras_pos_embd.pos_embd import PositionEmbedding
from keras_layer_normalization.layer_normalization import LayerNormalization
from keras_multi_head.multi_head_attention import MultiHeadAttention
from keras_position_wise_feed_forward.feed_forward import FeedForward
from keras_bert.bert import gelu_tensorflow

model = load_model('/home/gswyhq/hello-world/bert/model.h5', custom_objects={'TokenEmbedding':TokenEmbedding,
                                                                             'PositionEmbedding': PositionEmbedding,
                                                                             'LayerNormalization': LayerNormalization,
                                                                             'MultiHeadAttention': MultiHeadAttention,
                                                                             'FeedForward': FeedForward,
                                                                             'gelu_tensorflow': gelu_tensorflow})

ValueError: Unknown layer: Attention
#这里需要注意两点，
#1、是'Attention',这里对应了model.summary()打印的attention_1层的type
#2、AttentionLayer是class Attention实例化出来的对象

# 梯度消失与梯度爆炸、Loss为Nan的原因
1.梯度爆炸。梯度变得非常大，使得学习过程难以继续。
2.不当的损失函数。
3.不当的输入。if np.isnan(data).any(): continue
4.池化层中步长比卷积核的尺寸大。

在导入_obtain_input_shape时
from keras.applications.imagenet_utils import _obtain_input_shape

出现错误如下：
ImportError: cannot import name '_obtain_input_shape'
原因是在keras 2.2.2中，keras.applications.imagenet_utils模块不再有_obtain_input_shape方法。解决方法：
将导入语句修改如下
from keras_applications.imagenet_utils import _obtain_input_shape

keras可视化时报错：
  File "/usr/local/lib/python3.5/dist-packages/pydot.py", line 136, in call_graphviz
    **kwargs
  File "/usr/lib/python3.5/subprocess.py", line 947, in __init__
    restore_signals, start_new_session)
  File "/usr/lib/python3.5/subprocess.py", line 1551, in _execute_child
    raise child_exception_type(errno_num, err_msg)
FileNotFoundError: [Errno 2] No such file or directory: 'dot'

解决方法：
# apt-get install graphviz
# dot -V
dot - graphviz version 2.38.0 (20140413.2041)

利用model.fit_generator训练，并且可视化训练过程时，报错：
  File "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py", line 912, in on_epoch_end
    raise ValueError("If printing histograms, validation_data must be "
ValueError: If printing histograms, validation_data must be provided, and cannot be a generator.

解决方法：
直接把histogram_freq设置为0即可，histogram_freq，按照何等频率（epoch）来计算直方图，0为不计算
tbCallBack = TensorBoard(log_dir=TENSORBOARD_PATH, histogram_freq=0,  
                  write_graph=True, write_images=True)

在使用GPU训练时报错：
tensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(6368, 125), b.shape=(125, 125), m=6368, n=125, k=125

原因及解决方案：
这是调用GPU时，显存分配遇到了问题，所以发生错误。
比较保险的方式是在模型训练之前为tensorflow或者keras分配显存空间，tensorflow就用如下语句创建session：
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)  
sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))  
而keras就在引入keras时进行参数设置：
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.allocator_type = 'BFC' #A "Best-fit with coalescing" algorithm, simplified from a version of dlmalloc.
config.gpu_options.per_process_gpu_memory_fraction = 0.3
config.gpu_options.allow_growth = True
set_session(tf.Session(config=config)) 
如果使用ipython notebook，做完上述设置后可能出现GPU sync failed，重启一下就应该没问题了。

构建模型时报错：
TypeError: Layer reshape_1 does not support masking, but was passed an input_mask: Tensor("concatenate_1/All:0", shape=(?, ?), dtype=bool)
解决方案：
添加一个lambda层`dense = Lambda(lambda x: x, output_shape=lambda s: s)(dense)`使网络结构由
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 200)         240800
_________________________________________________________________
attention_1 (Attention)      (None, None, 128)         76800
_________________________________________________________________

变为：
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 200)         240800
_________________________________________________________________
lambda_1 (Lambda)            (None, None, 200)         0
_________________________________________________________________
attention_1 (Attention)      (None, None, 128)         76800
_________________________________________________________________


其他类似操作有：
添加一个lambda层`output = Lambda(lambda x: x[:, 0])(output)`使网络结构由
__________________________________________________________________________________________________
attention_1 (Attention)         (None, None, 512)    1572864     Encoder-1-FeedForward-Norm[23][0]
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 73)           37449       lambda_1[0][0]
__________________________________________________________________________________________________
变为：
__________________________________________________________________________________________________
attention_1 (Attention)         (None, None, 512)    1572864     Encoder-1-FeedForward-Norm[23][0]
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 512)          0           attention_1[0][0]
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 73)           37449       lambda_1[0][0]
__________________________________________________________________________________________________

当一个包含keras模型的python脚本执行时，如果没有任何多线程/多处理功能，它将可以正常工作。但是，一旦使用了多线程并且keras模型需要在新线程中执行，就会引起问题。
tornado启动服务，单线程启动加载模型没有问题；但改成多线程出现下面的问题：
ValueError: Tensor Tensor("ner_out/cond/Merge:0", shape=(?, ?, 125), dtype=float32) is not an element of this graph.
解决方案：
初始化加载模型后，先执行一次model._make_predict_function()操作，之后的调用就不会出问题了
model = load_model(filepath=model_path)
model._make_predict_function()

或者多线程报错：
ValueError: Tensor("training/Adam/Const:0", shape=(), dtype=float32) must be from the same graph as Tensor("sub:0", shape=(), dtype=float32).
解决方案：
加载模型时候：
    self.model = load_model(model_path)
    self.model._make_predict_function()
    self.graph = tf.get_default_graph()

预测的时候：
    with self.graph.as_default():
        labels = self.model.predict(data)

训练的时候：
    with self.graph.as_default():
        hist = self.model.fit(x, y)

