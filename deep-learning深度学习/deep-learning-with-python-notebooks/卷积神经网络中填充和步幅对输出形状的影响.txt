
一般来说,假设输入形状是 nh × nw ,卷积核窗口形状是 kh × kw ,那么输出形状将会是
(nh − kh + 1) × (nw − kw + 1).
所以卷积层的输出形状由输入形状和卷积核窗口形状决定。

一般来说,如果在高的两侧一共填充 ph 行,在宽的两侧一共填充 pw 列,那么输出形状将会是
(nh − kh + ph + 1) × (nw − kw + pw + 1),
也就是说输出的高和宽分别会增加 ph 和 pw 。
在很多情况下,我们会设置 ph = kh − 1 和 pw = kw − 1 使得输入和输出具有相同的高和宽。这
样会方便在构造网络时推测每个层的输出形状。假设这里 kh 是奇数,我们会在高的两侧分别填
充 ph /2 行。如果 kh 是偶数,一种可能是在输入的顶端一侧填充 ⌈ph /2⌉ 行,而在底端一侧填充
⌊ph /2⌋ 行。在宽的两侧填充同理。
卷积神经网络经常使用奇数高宽的卷积核,例如 1、3、5 和 7,所以填充在两端上的数目相同。

一般来说,当高上步幅为 sh ,宽上步幅为 sw 时,输出形状为
⌊(nh − kh + ph + sh )/sh ⌋ × ⌊(nw − kw + pw + sw )/sw ⌋.
如果我们设置 ph = kh − 1 和 pw = kw − 1,那么输出形状将简化为 ⌊(nh + sh − 1)/sh ⌋ × ⌊(nw +
sw − 1)/sw ⌋。更进一步,如果输入的高和宽能分别被高和宽上的步幅整除,那么输出形状将是
(nh /sh ) × (nw /sw )。

注： 向下取整的运算称为Floor，用数学符号⌊⌋表示；向上取整的运算称为Ceiling，用数学符号⌈⌉表示。

资料来源：动⼿学深度学习.pdf p147-p150