
增量学习分为三种：增量学习可以分为3类：样本增量学习（SIL），类别增量学习（CIL），特征增量学习（FIL）
1、SIL
问题：由于新数据的各种原因，样本的特征值可能会改变，每个类别的比例也会改变。这些都会影响分类的准确率。
任务：因此，需要确保在现有知识的情况下，通过新样本的增量学习来提取新知识，融合新旧知识以提高分类的准确性。
2、 CIL
任务：识别新类，并将其加入现有类别的集合中，提升分类的准确性和智能。
3、FIL
一些新的属性特征能够将分类提升到一个很大的程度，并提升分类准确率。
任务：在现有特征空间的基础上，加入新的属性特征，构建新的特征空间，提升分类准确率。

1、增量学习和迁移学习的区别：
迁移学习是从一个学习任务迁移到另一个学习任务，根据源数据的相似程度和训练数据量的大小，来决定是微调还是调整全部的层的权重。
而增量学习主要思想在于学习新知识，它相当于一个好学生，学习新知识的同时不会忘记旧知识，比如原模型可以识别圆形，经过增量学习，学习如何识别三角形，那么改模型现在就可以学习圆形和三角形两种形状了，而迁移学习则把学习三角形当成一个新任务，之前的旧知识旧忘掉了。

2、增量学习和Keras fit_genetor 的区别：
严格来讲两者是没有任何联系的，但是可能会混淆概念，增量学习的样本增量学习（SIL）可以理解为fit_genetor的训练，因为数据量太大，无法一次加载到内存，但是又不想进行抽样，抽样数据可能无法代表整体数据的分布（特别当数据是偏斜的），这时候增量学习就相当于每次取其中的一部分数据进行训练，这样持续多次就可以把全部的数据学习完成。
而fit_genetor也是这个原理，只不过Keras一般只用于神经网络，对于传统的机器学习方法就无计可施了，而增量学习就是解决的这个问题，Keras应该也是从增量学习学到的技巧。

tensorflow在原有模型的基础进行训练也可以理解是样本的增量学习：
saver = tf.train.Saver()
sess = tf.Session(graph=graph)
check_point_path = 'saved_model/' # 保存好模型的文件路径
ckpt = tf.train.get_checkpoint_state(checkpoint_dir=check_point_path)
saver.restore(sess,ckpt.model_checkpoint_path)

