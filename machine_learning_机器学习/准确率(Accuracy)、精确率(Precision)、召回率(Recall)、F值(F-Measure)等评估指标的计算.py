#!/usr/bin/python3
# coding: utf-8

import numpy as np
from sklearn.metrics import f1_score, accuracy_score, fbeta_score, precision_score, recall_score
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score

# 真实标签
y_true = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]

# 模型预测结果
y_test = [0.8453712241207609, 0.8365137845084419, 0.8396024690959464, 0.8690716625950063, 0.801398983655787, 0.8353417405844167, 0.8887589815396711, 0.8274617726584338, 0.8901324702288052, 0.8515827665762914, 0.8008748432690203, 0.9129143613344268, 0.8213637332093631, 0.7926672650384551, 0.8715962551942291, 0.865989576549353, 0.8487118383625984, 0.893722366823937, 0.8683798090835637, 0.8258107838161615, 0.9067962552630583, 0.8896577622207299, 0.8287242449131549, 0.862162050742874, 0.9145984088092137, 0.8195240228832353, 0.8627208683955114, 0.8667420865435141, 0.833175478131922, 0.8338735760735464, 0.8609573544733866, 0.8270040835455006, 0.8438342928159803, 0.9162216060491829, 0.8681943043237748, 0.825237777063406, 0.9309199493779501, 0.847918698600505, 0.885842165942269, 0.845606331185933, 0.8867428557974891, 0.8569372316111383, 0.8374900840504085, 0.8495098728280119, 0.8475137546498668, 0.8509974354378016, 0.8545542968912262, 0.8369359268265817, 0.8881628216627452, 0.8553054247582024, 0.8715475068300871, 0.8608489638331329, 0.7871896522021451, 0.7986180814516614, 0.8679817198115483, 0.8555312604259576, 0.8737131993516944, 0.8570307159808236, 0.86943760267903, 0.8155454038368009, 0.8284627670247386, 0.7440460226630737, 0.8383901711678877, 0.9176876584197461, 0.8867356968591616, 0.8800298236584221, 0.8534696245512979, 0.9166524864925935, 0.8205450625187547, 0.8235830983361883, 0.8610359125511253, 0.8534495672661243, 0.8343550724006359, 0.826657313239454, 0.8327557274202153, 0.8263809690050867, 0.8449533999089178, 0.7403854533869694, 0.8862881836134406, 0.80930312554624, 0.8390349727384677, 0.7812820207595776, 0.8405256568966404, 0.7208619973606759, 0.8237972236612818, 0.8652031422452744, 0.7788070757633151, 0.8795942431527423, 0.8603826742129177, 0.83330392945359, 0.8487413534443429, 0.8085704307615089, 0.8862416492592033, 0.8154708608934949, 0.8949611666064037, 0.8189329260750865, 0.8328395987596068, 0.9158502403398057, 0.8066900361300818, 0.9277331317048729]

thre = 0.874 # 随机定义一个阈值

tp = 0  # 正真
tn = 0  # 真负
fp = 0  # 假正
fn = 0  # 假负

for t4, t5 in zip(y_true, y_test):
    if t4 == 1 and t5 >= thre:
        tp += 1
    elif t4 == 1:
        fn += 1
    elif t4 == 0 and t5 < thre:
        tn += 1
    else:
        fp += 1

data = {
    "真正": tp,
    "真负": tn,
    "假正": fp,
    "假负": fn
}
print("混淆矩阵数据：", data)

p = tp / (tp + fp )  # 精确率，预测为正的样本中有多少是真正的正样本
r = tp / (tp + fn )  # 召回率，样本中的正例有多少被预测正确了
acc = (tp + tn) / (tp + tn + fp + fn)  # 准确率，被分对的样本数除以所有的样本数
f1 = 2 * p * r / (p + r )

beta = 2
#       (1 + β × β) × P × R
# Fβ = ──────────────────────
#        (β × β) × P + R

f2 = (1+beta*beta) * p * r / (beta*beta*p+r)

data2 = {
    "准确率": acc,
    "精确率": p,
    "召回率": r,
    "f1值": f1,
    "f2值": f2,
}

print('通过精确率，召回率计算的结果：', data2)

# auc
auc = roc_auc_score(y_true, y_test)

# 精确率
p = precision_score(y_true, np.array(y_test)>thre)

# 召回率
r = recall_score(y_true, np.array(y_test) > thre)

# acc
acc = accuracy_score(y_true, np.array(y_test) > thre)

f1 = f1_score(y_true, np.array(y_test) > thre)

f2 = fbeta_score(y_true, np.array(y_test) > thre, beta=2)

data3 = {
    "准确率": acc,
    "ROC曲线下面积": auc,
    "f1值": f1,
    "f2值": f2,
    "精确率": p,
    "召回率": r,
}

print('通过sklearn计算的结果：', data3)

y_true = [0, 1, 2, 2, 2]
y_test = [0, 0, 2, 2, 1]
target_names = ['class 0', 'class 1', 'class 2']
print(classification_report(y_true, y_test, target_names=target_names))


def main():
    pass


if __name__ == '__main__':
    main()