

混淆矩阵
True Positive(真正，TP)：将正类预测为正类数
True Negative(真负，TN)：将负类预测为负类数
False Positive(假正，FP)：将负类预测为正类数误报 (Type I error)
False Negative(假负，FN)：将正类预测为负类数→漏报 (Type II error)

                      预测列表
              YES             NO              总计
实际   YES     TP              FN              P(实际为YES)
类别   NO      FP              TN              N(实际为NO)
      总计     P'(被分为YES)    N'(被分为NO)     P+N

1、准确率（Accuracy）
准确率(accuracy)计算公式为：acc = (真正+真负)/(真正+真负+假真+假负) = (TP+TN)/(TP+TN+FP+FN)

注：准确率是我们最常见的评价指标，而且很容易理解，就是被分对的样本数除以所有的样本数，通常来说，正确率越高，分类器越好。
准确率确实是一个很好很直观的评价指标，但是有时候准确率高并不能代表一个算法就好。比如某个地区某天地震的预测，假设我们有一堆的特征作为地震分类的属性，类别只有两个：0：不发生地震、1：发生地震。
一个不加思考的分类器，对每一个测试用例都将类别划分为0，那那么它就可能达到99%的准确率，但真的地震来临时，这个分类器毫无察觉，这个分类带来的损失是巨大的。
为什么99%的准确率的分类器却不是我们想要的，因为这里数据分布不均衡，类别1的数据太少，完全错分类别1依然可以达到很高的准确率却忽视了我们关注的东西。
因此，单纯靠准确率来评价一个算法模型是远远不够科学全面的。

2、错误率（Error rate）
错误率则与准确率相反，描述被分类器错分的比例，error rate = (FP+FN)/(TP+TN+FP+FN)，对某一个实例来说，分对与分错是互斥事件，所以accuracy =1 - error rate。

3、灵敏度（sensitive）
sensitive = (真正)/(真正+假负) = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力。

4、特效度（sensitive）
specificity = (真负)/(真负+假正) = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力。

5、精确率、精度（Precision）
精确率(precision rate)是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。
那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是精确率；
精确率(precision) = (真正)/(真正+假正) = TP /(TP + FP)

6、召回率(recall rate)是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。
那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。
召回率是覆盖面的度量，度量有多个正例被分为正例，recall=TP/(TP+FN)=TP/P=sensitive，可以看到召回率与灵敏度是一样的。

在信息检索领域，精确率和召回率又被称为查准率和查全率，
查准率＝检索出的相关信息量 / 检索出的信息总量
查全率＝检索出的相关信息量 / 系统中的相关信息总量

7、综合评价指标（F-Measure）
P(精确率)和R(召回率)指标有时候会出现的矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure（又称为F-Score）。
F-Measure是Precision和Recall加权调和平均：
         (α×α+1) × P × R
F = ─────────────────────────
             α×α×(P+R)

当参数α=1时，就是最常见的F1，也即
         2 × P × R
F1 = ──────────────────
           P+R

可知F1综合了P和R的结果，当F1较高时则能说明试验方法比较有效。

8、其他评价指标
计算速度：分类器训练和预测需要的时间；
鲁棒性：处理缺失值和异常值的能力；
可扩展性：处理大数据集的能力；
可解释性：分类器的预测标准的可理解性，像决策树产生的规则就是很容易理解的，而神经网络的一堆参数就不好理解，我们只好把它看成一个黑盒子。

8.1、ROC曲线：
ROC（Receiver Operating Characteristic）曲线是以假正率（FP_rate）和假负率（TP_rate）为轴的曲线，ROC曲线下面的面积我们叫做AUC
8.2、PR曲线：
即，PR（Precision-Recall）曲线。

二.举个栗子
假设我们手上有60个正样本，40个负样本，我们要找出所有的正样本，系统查找出50个，其中只有40个是真正的正样本，计算上述各指标。

TP: 将正类预测为正类数 40
FN: 将正类预测为负类数 20
FP: 将负类预测为正类数 10
TN: 将负类预测为负类数 30

准确率(accuracy) = 预测对的/所有 = (TP+TN)/(TP+FN+FP+TN) = 70%
精确率(precision) = TP/(TP+FP) = 80%
召回率(recall) = TP/(TP+FN) = 2/3

一般评分以F1-score为准，得分相同时，参照accuracy排序。
参考：https://blog.csdn.net/dzzzzzzzzzz/article/details/83316271
https://dc.cloud.alipay.com/index#/topic/data?id=8

